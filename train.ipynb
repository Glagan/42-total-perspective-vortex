{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "import mne\n",
    "from mne import Epochs, pick_types, annotations_from_events, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP, SPoC\n",
    "from mne.viz import plot_events, plot_montage\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs, corrmap, Xdawn\n",
    "\n",
    "mne.set_log_level(\"CRITICAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -1.0, 4.0\n",
    "subjects_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        \"runs\": [3, 7, 11],\n",
    "        \"mapping\": {0: \"rest\", 1: \"left fist\", 2: \"right fist\"},\n",
    "    },\n",
    "    {\n",
    "        \"runs\": [4, 8, 12],\n",
    "        \"mapping\": {0: \"rest\", 1: \"imagine left fist\", 2: \"imagine right fist\"},\n",
    "    },\n",
    "    {\n",
    "        \"runs\": [5, 9, 13],\n",
    "        \"mapping\": {0: \"rest\", 1: \"both fists\", 2: \"both feets\"},\n",
    "    },\n",
    "    {\n",
    "        \"runs\": [6, 10, 14],\n",
    "        \"mapping\": {0: \"rest\", 1: \"imagine both fists\", 2: \"imagine both feets\"},\n",
    "    },\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # {\n",
    "    #     \"runs\": [3, 7, 11, 4, 8, 12],\n",
    "    #     \"mapping\": {0: \"rest\", 1: \"left fist\", 2: \"right fist\"},\n",
    "    # },\n",
    "    # {\n",
    "    #     \"runs\": [5, 9, 13, 6, 10, 14],\n",
    "    #     \"mapping\": {0: \"rest\", 1: \"both fists\", 2: \"both feets\"},\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial models\n",
    "models = []\n",
    "for i in range(4):\n",
    "    csp = CSP(n_components=8)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    clf = Pipeline([(\"CSP\", csp), (\"LDA\", lda)])\n",
    "    models.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject #1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m cv_split \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39msplit(epochs_data_train)\n\u001b[1;32m     58\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m models[model_id]\u001b[39m.\u001b[39;49mfit(epochs_data, labels)\n\u001b[1;32m     61\u001b[0m \u001b[39m# Score\u001b[39;00m\n\u001b[1;32m     62\u001b[0m score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(models[model_id], epochs_data, labels, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/base.py:862\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m, in \u001b[0;36mCSP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the CSP model.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m        The CSP instance.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m     n_trials, n_channels, n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m     42\u001b[0m     class_means \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/mambaforge/envs/mne/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m     )\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    921\u001b[0m     _assert_all_finite(\n\u001b[1;32m    922\u001b[0m         array,\n\u001b[1;32m    923\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "all_accuracies = []\n",
    "all_cross_accuracices = []\n",
    "for subject in range(1, subjects_count + 1):\n",
    "    print(f\"Subject #{subject}\")\n",
    "\n",
    "    for model_id, experiment in enumerate(experiments):\n",
    "        raw_fnames = [f\"dataset/S{subject:03d}/S{subject:03d}R{run:02d}.edf\" for run in experiment[\"runs\"]]\n",
    "        raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "        events, _ = events_from_annotations(raw, event_id=dict(T1=1, T2=2))\n",
    "        annot_from_events = annotations_from_events(\n",
    "            events=events, event_desc=experiment[\"mapping\"], sfreq=raw.info[\"sfreq\"]\n",
    "        )\n",
    "        raw.set_annotations(annot_from_events)\n",
    "        eegbci.standardize(raw)  # set channel names\n",
    "        montage = make_standard_montage(\"biosemi64\")\n",
    "        raw.set_montage(montage, on_missing='ignore')\n",
    "\n",
    "        # Select channels\n",
    "        channels = raw.info[\"ch_names\"] \n",
    "        good_channels = [\n",
    "            \"FC3\",\n",
    "            \"FC1\",\n",
    "            \"FCz\",\n",
    "            \"FC2\",\n",
    "            \"FC4\",\n",
    "            \"C3\",\n",
    "            \"C1\",\n",
    "            \"Cz\",\n",
    "            \"C2\",\n",
    "            \"C4\",\n",
    "            \"CP3\",\n",
    "            \"CP1\",\n",
    "            \"CPz\",\n",
    "            \"CP2\",\n",
    "            \"CP4\",\n",
    "            \"Fpz\",\n",
    "        ]\n",
    "        bad_channels = [x for x in channels if x not in good_channels]\n",
    "        raw.drop_channels(bad_channels)\n",
    "\n",
    "        # Filter\n",
    "        raw.notch_filter(60, method=\"iir\")\n",
    "        raw.filter(7, 32.0, fir_design=\"firwin\", skip_by_annotation=\"edge\") \n",
    "\n",
    "        # Read epochs\n",
    "        events, event_id = events_from_annotations(raw)\n",
    "        picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "        epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)\n",
    "        epochs_train = epochs.copy().crop(tmin=1.0, tmax=2.0)\n",
    "        labels = epochs.events[:, -1]\n",
    "\n",
    "        # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "        epochs_data = epochs.get_data()\n",
    "        epochs_data_train = epochs_train.get_data()\n",
    "        cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "        # Train\n",
    "        models[model_id].fit(epochs_data, labels)\n",
    "\n",
    "        # Score\n",
    "        score = np.mean(cross_val_score(models[model_id], epochs_data, labels, cv=cv, n_jobs=None, verbose=False))\n",
    "        accuracy = accuracy_score(labels, models[model_id].predict(epochs_data))\n",
    "        print(f\"[Training] Accuracy: {accuracy:.2%} (score: {score:.2%})\")\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_cross_accuracices.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracy: {np.mean(all_accuracies):.2%} (score: {np.mean(all_cross_accuracices):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "for i in range(4):\n",
    "    print(joblib.dump(models[i], f\"models/model_{i}.z\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de53c2a5f3662977df581daedca7ffd392916b4fc8ed6ed2b00e9b2d99e942aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
